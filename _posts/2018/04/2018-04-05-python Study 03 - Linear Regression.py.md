---
layout: post
title: "골빈 해커의 3분 딥러닝∥03 - Linear Regression.py 공부"
date: 2018-04-06
image: ''
description: 'Deep Learning Study'
tags:
- python
- Deep Learning
- Machine Learning
- TensorFlow
categories:
- python
- Study
description: 
---
참고 : [골빈 해커의 3분 딥러닝](https://github.com/golbin/TensorFlow-Tutorials/tree/master/03%20-%20TensorFlow%20Basic), [머신러닝 강좌 동영상- Youtube 동빈나](https://www.youtube.com/watch?v=IhNNpyWKorY)
하루를 정리하는 느낌으로 오늘 장시간에 걸쳐서 이해한 **선형회귀법**에 관해 포스팅을 하려한다. 물론 베이스는 맨 위에 링크되어있는 **골빈 해커의 3분 딥러닝 소스 코드**를 바탕으로 본문을 작성하려고 한다.

일단 무작정 닥치는대로 정보를 끌어모아 공부하는 방법으로 무난한 대학교 생활을 보내고 있는 나에게 있어서는 기초적인 지식보다 한번 해보고 눈으로 직접 보자는것이 더 중요하다고 생각되었다. 

이론을 바탕으로 한 실습보다는 적당한 이론을 베이스로 일단 실습을 한 뒤 다시 이론을 돌아보는 형식으로써 학술적 가치는 없다고 본다. 왜냐하면 딱히 조사하지도 않았을 뿐더러 그냥 헛소리이기 때문이다
- - -
##Linear Regression(선형 회귀)
일단 선형 회귀를 들어가기전에, 회귀 분석이라는 것을 짚고 넘어가자.
[회귀분석 위키피디아](https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D)에 따르면
>통계학에서, 회귀분석(回歸分析, 영어: regression analysis)은 관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한뒤 적합도를 측정해 내는 분석 방법이다.
>
회귀분석은 시간에 따라 변화하는 데이터나 어떤 영향, 가설적 실험, 인과 관계의 모델링등의 통계적 예측에 이용될 수 있다. 그러나 많은 경우 가정이 맞는지 아닌지 적절하게 밝혀지지 않은 채로 이용되어 그 결과가 오용되는 경우도 있다. 특히 통계 소프트웨어의 발달로 분석이 용이해져서 결과를 쉽게 얻을 수 있지만 적절한 분석 방법의 선택이였는지 또한 정확한 정보 분석인지 판단하는 것은 연구자에 달려 있다.

라고 쓰여져 있다.
***잘 모르겠다.*** 그래서 간단하게 예제를 들어서 설명해보려 한다.
예를들어 본인이 겨울철에 길거리에서 **군고구마**를 장사한다고 가정해보자

![군고구마](https://user-images.githubusercontent.com/37685852/38466098-eaf7b336-3b5e-11e8-9d2e-d44218906ceb.png)
>[군고구마 출처](https://xperience.link/ko/article/%EC%9D%B4%EB%B0%94%EB%9D%BC%ED%82%A4%EC%9D%98-%ED%8A%B9%EC%82%B0%ED%92%88-%EB%A7%9B%EC%9E%88%EC%96%B4%EC%84%9C-%EB%A9%88%EC%B6%9C%EC%88%98-%EC%97%86%EB%8A%94-%EA%B5%B0%EA%B3%A0%EA%B5%AC%EB%A7%88-%ED%8F%AC%ED%85%8C%ED%86%A0%EC%B9%B4%EC%9D%B4%EC%B8%A0%EC%B9%B4) 무려 이바라키 특산품

예를들어 10일간 장사를 하였을때, 10일 전부 기온이 각각이며, 왠지 기온에 따라 군고구마의 판매량이 달라진다는 이상한 느낌이 들어 매출 데이터를 보고 통계학적으로 접근해보려 한다.
> 
기온 : 10도, 판매량 : 90개 
기온 : 9도, 판매량 : 106개
기온 : 8도, 판매량 : 121개 
기온 : 7도, 판매량 : 131개 
기온 : 6도, 판매량 : 149개 
기온 : 5도, 판매량 : 181개 
기온 : 4도, 판매량 : 186개 
기온 : 3도, 판매량 : 192개 
기온 : 2도, 판매량 : 201개 
기온 : 1도, 판매량 : 212개 

판매량을 보고 이상함을 감지한 군고구마 장수는 기온과 판매량의 상관관계를 알아보려고 한다. 

기온을 X, 판매량을 Y라고 두었을때, 기온이 0도가 되는 내일의 판매량을 알고싶어진 군고구마 장수. 이럴 때 판매량 데이터를 바탕으로 회귀분석을 행할 수 있다.
![graph](https://user-images.githubusercontent.com/37685852/38466115-2c81b3d8-3b5f-11e8-8539-18cad172e191.png)

일단 기온을 켈빈으로 변환하여, 각 기온에 따른 판매량을 그래프로 나타내고, 엑셀 기본 기능인 근사곡선을 선형으로 선택하여 그래프에 출력을 해보았다.

그래프 상의 점선을 회귀식이라고 하고, 보다싶이 직선의 방정식인

####Y = aX + b
로 나타내는것이 가능하다.

실제로 엑셀에서는 a값과 b값을 구하여 표시해주고 있다. 어떤 방식으로 산출한 것인지는 구글에게 물어보자

보통 어떠한 알고리즘이 있어야 결과 데이터를 얻고 싶어한다. a 와 b 를 알고있는 상태에서 독립변수인 X값(입력)을 넣어 종속변수인 Y값(출력)을 얻는게 일반적이다.

하지만 딥러닝과 같은 신경망에서는 입력데이터와 결과데이터의 상관관계를 분석하여 알고리즘을 산출해 내는데 회귀분석 또한 마찬가지이다. 기존의 데이터를 사용하여 회귀식을 만들어 내는 것이다.

회귀분석에는 여러가지 종류가 있으나 본 게시물에서는 ***선형 회귀***에 관해서 이야기 하려고 한다.
  
  
  
- - -
  
  
####[선형회귀](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)
아까 설명했다 싶이 X와 Y의 선형 상관 관계를 모델링하는 회귀 분석 기법이다.
선형 회귀 모델 추정 기법에는 여러가지가 있고, 골빈 3분 딥러닝에서는 경사 하강법 최적화를 사용하여 TensorFlow 예제를 작성하였다.
> [경사 하강법](https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95)
> 경사 하강법(傾斜下降法, Gradient descent)은 1차 근삿값 발견용 최적화 알고리즘이다. 기본 아이디어는 함수의 기울기(경사)를 구하여 기울기가 높은 쪽으로 계속 이동시켜서 극값에 이를 때까지 반복시키는 것이다.

무슨 소린지 잘 이해가 안가면 유투브 [여기](https://www.youtube.com/watch?v=YK9PNTJ_aFA&feature=youtu.be&t=2m11s) 를 참고해보자
역시 이론보다 보는게 빠름

일단 코드를 샅샅이 살펴보자
```python
import tensorflow as tf
x_data = [1, 2, 3]
y_data = [1, 2, 3] ```
이 부분에 있어서는 별다른 설명이 필요하지 않을 듯하다.
TensorFlow를 tf로 불러오고, 입력인 X 데이터와 출력인 Y 데이터를 설정해 놓는다. 결과적으로 말한다면 이 소스코드는 X와  Y와의 상관관계에서 임의의 X값에 대해서는 어떤 결과 Y값이 나오는가 에 대해 학습하는 프로그래밍이다

현재 입력되어진 데이터는 
기온(x_data)가 1도일때, 군고구마 판매량(y_data)가 1개 팔렸고,  
기온(x_data)가 2도일때, 군고구마 판매량(y_data)가 2개 팔렸고, 
기온(x_data)가 3도일때, 군고구마 판매량(y_data)가 3개 팔렸고,
기온(x_data)가 100도이면, 군고구마 판매량(y_data)는 얼마? 라는걸 기계에게 도출해 내라는 프로그래밍이다.

일단 쉬운 값들이니므로 회귀식의 a와 b는 당연히 
a=1 , b=0 이 나와야 정상이다.
y=x 이므로.

일단 넘어가고 다음 코드를 보자.
```python
W = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) 
b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))```
```tf.Variable``` 에 관해서는 아직 포스팅전이지만, 02번 튜토리얼에서 볼 수 있다.
대략적으로 이해한 바로는, 그래프를 계산하면서 최적화 할 변수들이며, 이 값이 바로 신경망을 좌우하는 값이라고 한다.

그 오른쪽으로 ```tf.random_normal ```이 있는데, 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화 하는 함수이다.

정리하자면 W와 b를 선언 후, 1x1 행렬에 -1부터 1까지의 값을 랜덤하게 할당한다는 내용.

W값과 b값의 범위를 넓게하면 할 수록 학습하는데 어려움이 있을것이고 그럴때는 여러 대의 머신을 이용하여 병렬 계산을 해야하겠지? 그래서 일단 -1에서 1사이의 랜덤한 수를 할당해 주었다.  틀렸다. 난수 할당은 초기에만 실행되므로 문제없다. 나는 매번 값을 제시할때마다 난수값을 할당하는줄. 하긴 그러면 머신러닝이 아니라 그냥 난수 대입이구나.

여기서 난수를 사용하는 가장 중요한 의도는, 최저 비용을 스스로 찾아가야 하는데, 시작 위치가 매번 프로그램을 실행할 때마다 달라짐에도 불구하고 항상 최저비용을 찾아간다는 것을 보여주기 위함이다. 실제로 -1에서 1사이의 범위의 값이 아니라 상수를 할당해도 머신 러닝은 놀랍게도 저비용의 절편을 찾아간다. 참고

다음으로 넘어가자
```python
X = tf.placeholder(tf.float32, name=“X”)
Y = tf.placeholder(tf.float32, name=“Y”)
print(X)
print(Y) ```

```.placeholder()```로 이름을 할당해준것은 그냥 나중에 TensorBoard로 확인을 하기 위함이라고 써져있다. 별 중요하지 않으니 넘어가자.
```python
hypothesis = W * X + b 
```
자 이제 가설을 세우자. **Hypothesis** 하이포thㅓ시스 는 가설이라는 뜻이다.
여기서 W와 b에 대한 의문이 들을 수도 있지만, 앞서 말한 a가 W이고 b가 b인것이다. 

W는 가중치이며, b는 편향이라고 하나 이것은 인공신경망(Neural Network)의 기본 개념이므로 [여기](https://laonple.blog.me/220489989951) 를 참고하자. 인터넷 미리보기로 골빈 3분 딥러닝의 4장을 잠깐 보면 개념이 나오기도 한다. 사실 몇장인지 잘 모르겠지만 아무튼.

